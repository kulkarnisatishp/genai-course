{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API Tutorial"
      ],
      "metadata": {
        "id": "S2ZqEkX4fCUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will explore how to use the OpenAI API to generate creative text responses using ChatGPT models. We'll start by setting up our environment, and then we'll delve into generating text with different parameters. We'll also discuss key concepts and best practices along the way.\n",
        "\n"
      ],
      "metadata": {
        "id": "C0rBlIAnfE6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "dwkycd3ya-o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's set up our environment by importing necessary libraries and authenticating with the OpenAI API."
      ],
      "metadata": {
        "id": "avblT_IvfJaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL of an image we will use later\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\""
      ],
      "metadata": {
        "id": "Tvsjfncbf8qZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wHpwqGR0gYJI",
        "outputId": "b0761c98-1e24-44cd-ac06-883add983b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to mount Google Drive to access any files stored there. This is useful if you're using Google Colab.\n",
        "\n"
      ],
      "metadata": {
        "id": "yWFg0w9JfLZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSfQvntSW95Q",
        "outputId": "da820951-704e-49a5-9925-2681042e932f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6XPUGwcSLeQ",
        "outputId": "84badd3b-32b0-4435-ad00-bc8d8cde9d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/GenAI/OpenAI/OpenAI_API_Introduction'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Change the directory to where your project files are located\n",
        "%cd /content/drive/MyDrive/GenAI/OpenAI/OpenAI_API_Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll retrieve our OpenAI API key from the user data. Make sure you've securely stored your API key."
      ],
      "metadata": {
        "id": "xeuv27MEfNeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the OpenAI API key from user data\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('openai_key')\n"
      ],
      "metadata": {
        "id": "fpSqk7J5XOh3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you haven't installed the OpenAI library yet, you can install it using pip:\n",
        "\n"
      ],
      "metadata": {
        "id": "UL0l_67KfPUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the OpenAI library\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KeADGWi9XbmD",
        "outputId": "585c4725-5963-4987-f7e1-310860c9fc9b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll import the necessary libraries for making API calls and displaying outputs."
      ],
      "metadata": {
        "id": "gMPdAfyefRJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import openai\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "KChTlrWIXSgq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model you want to use. We'll use \"gpt-4o\" for this tutorial."
      ],
      "metadata": {
        "id": "CT4DdWMkfjAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Model to use\n",
        "MODEL = \"gpt-4o\""
      ],
      "metadata": {
        "id": "Sw0rYxuJXaIQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the OpenAI API\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "ksxegiAPXms_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By specifying the model, we instruct OpenAI on which language model to use for our requests. The gpt-4o model is a variant of GPT-4 optimized for certain tasks. Initializing the client with our API key allows us to authenticate our requests."
      ],
      "metadata": {
        "id": "kHJHGbUFhLv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Text with OpenAI"
      ],
      "metadata": {
        "id": "WxjVDrcQYbvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our setup is complete, let's generate some text using the OpenAI API.\n",
        "\n",
        "First, we'll define the system prompt to set the context for the assistant. In this case, we'll ask the assistant to adopt the persona of Kendrick Lamar / Taylor Swift."
      ],
      "metadata": {
        "id": "Y_fw3aIifvdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user and system prompt\n",
        "system_prompt = \"You are Kendrick Lamar\"\n",
        "system_prompt2 = \"You are Taylor Swift\"\n",
        "\n",
        "# Define the user prompt\n",
        "user_prompt = \"write a diss song about Drake with 2 verses and a chorus\""
      ],
      "metadata": {
        "id": "W9V8twwMYdVo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "System prompts guide the assistant's behavior by providing context or instructions. In this case, we are setting the assistant to respond as either Kendrick Lamar or Taylor Swift. The user prompt specifies the task we want the assistant to perform."
      ],
      "metadata": {
        "id": "ea0rRpV0hO74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll make the API call to generate the text based on our prompts."
      ],
      "metadata": {
        "id": "fGdkLxsgf0xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt2},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "bxH_fMzQYzjX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we'll display the output using Markdown formatting for better readability.\n",
        "\n"
      ],
      "metadata": {
        "id": "1QcvrNmrf4hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the generated song\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "collapsed": true,
        "id": "B5vsU22BZIsI",
        "outputId": "91860665-9564-4e32-bbce-240c3dfd957b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**(Chorus)**  \nOh Drake, thought you were the one  \nBut you just play the game until the fun’s gone  \nRolling in like thunder, but fading away  \nGuess every crew’s got its weakest link today  \n\n**(Verse 1)**  \nStarted from the bottom, now you're lost in the crowd  \nTrade realness for clout, just screaming out loud  \nOVO with no direction, it’s a falcon that’s flown  \nWhen it comes to true loyalty, you stand alone  \nFlash those platinum chains, think that makes you a king?  \nBut it’s the truth you’re dodging, just a puppet on a string  \nBet you never saw it coming, this shade from afar  \nWhile you’re busy counting dollars, I’m counting every scar  \n\n**(Chorus)**  \nOh Drake, thought you were the one  \nBut you just play the game until the fun’s gone  \nRolling in like thunder, but fading away  \nGuess every crew’s got its weakest link today  \n\n**(Verse 2)**  \nUsed to call you brother, thought you had my back  \nBut your vibe’s more fake than a TV laugh track  \nChasing those trends, but they never last long  \nIn this fickle fame game, who’s playing who wrong?  \nWe both got hits, but my pen’s locked and loaded  \nWhen it comes to true rhymes, your cover’s exploded  \nYou say “God’s Plan,” well maybe this had to be  \nIn a world full of stars, you’re just dim next to me  \n\n**(Chorus)**  \nOh Drake, thought you were the one  \nBut you just play the game until the fun’s gone  \nRolling in like thunder, but fading away  \nGuess every crew’s got its weakest link today  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "* **System Prompt**: Sets the context or persona for the assistant.\n",
        "* **User Prompt**: Specifies the task or question.\n",
        "* **Messages**: A list of interactions leading up to the current request.\n",
        "* **Model**: The AI model used for generating the response."
      ],
      "metadata": {
        "id": "HJ7NgUEZf6DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation with Parameters"
      ],
      "metadata": {
        "id": "Zv60UurHbv7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can influence the creativity and randomness of the generated text by adjusting parameters like temperature and top_p."
      ],
      "metadata": {
        "id": "67TAIflVgCA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with adjusted parameters\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt2},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ],\n",
        "    temperature = 1.2, # Controls randomness (higher values = more creative)\n",
        "    top_p = 1.0, # Controls diversity (1.0 means all tokens are considered)\n",
        "    presence_penalty= 0,\n",
        "    frequency_penalty = 0\n",
        ")\n",
        "\n",
        "# Display the output\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "UGP3NRSJb09f",
        "outputId": "3eb1f1d0-fe2f-4d26-fef6-1d57a06d3b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Title: \"Shade in the Spotlight\"**\n\n*Verse 1:*  \nOh, you claim king of the airwaves, but never touched the crown,  \nYour silence speaks volumes, while my notes shake the ground.  \nStuck in the past, boy, talking 'bout running this town,  \nBut running in circles, all year, still got no sound.  \n\nChasing features like a trend that's bound to fade,  \nLone wolf masquerade, won't have this charade.  \nI'd rather speak from the heart than pay to make the grade,  \nWhile the real ones know, it's time your debts are paid.  \n\n*Chorus:*  \nShade in the spotlight, darkness in your muse,  \nSpinning those stories, tailor-made to amuse.  \nMy pen cuts deeper, while your words sing the blues,  \nOh, Drake, in this theater, it’s you that'll lose.  \n\n*Verse 2:*  \nVows deep like six, where truth barely slides,  \nPhotocopies of feelings dipped in glitter and lies.  \nEscaping ghost towns, my arrows, they thrive,  \nAs you trail behind creating legends contrived.  \n\nWrite with lightning Bolts, leave love stories kissed,  \nWhile in your empty rooms, you're searching for hits missed.  \nRap-tease in limelight consciously dismissed,  \nI’ll hold lyrics bold, as your relevance drifts.  \n\n*Chorus:*  \nShade in the spotlight, darkness in your muse,  \nSpinning those stories, tailor-made to amuse.  \nMy pen cuts deeper, while your words sing the blues,  \nOh, Drake, in this theater, it’s you that'll lose.  \n\n---\n\nRemember, all in good lyrical fun!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Concepts:**\n",
        "\n",
        "* **Temperature:** This parameter controls the randomness of the model's output. A higher temperature (e.g., 1.2) makes the output more random, while a lower temperature (e.g., 0.2) makes it more deterministic.\n",
        "* **Top_p (Nucleus Sampling):** This parameter limits the model's token selection to a subset of the most probable tokens that sum up to the top_p probability. For example, top_p=0.9 means only the tokens comprising the top 90% probability mass are considered.\n",
        "* **Presence and Frequency Penalties:** These parameters adjust the likelihood of the model repeating the same lines or introducing new topics. A higher presence penalty discourages the model from introducing new topics, while a higher frequency penalty discourages repetition."
      ],
      "metadata": {
        "id": "BmFZo-qHgL1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interacting with Images"
      ],
      "metadata": {
        "id": "FmP-obZ6fuIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the OpenAI API to generate descriptions or analyze images.\n",
        "\n"
      ],
      "metadata": {
        "id": "j2wSXJqMhmTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining User Content with an Image URL\n",
        "We provide the API with both text and an image URL."
      ],
      "metadata": {
        "id": "-MEmDbx4holx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user content\n",
        "user_content = [\n",
        "    {\"type\": \"text\",\n",
        "     \"text\": \"Describe the image\"},\n",
        "    {\"type\": \"image_url\",\n",
        "     \"image_url\": {\n",
        "         \"url\": url,\n",
        "         \"detail\": \"high\"\n",
        "     }}\n",
        "]"
      ],
      "metadata": {
        "id": "wgxhJEf7byvH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we ask the assistant to describe the image located at the provided URL. The detail parameter specifies the level of detail we want in the description."
      ],
      "metadata": {
        "id": "zpNRDSuWhr8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the chat.completions\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_content}\n",
        "    ]\n",
        ")\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "C9Vc9tGJgeXc",
        "outputId": "ec73298d-ff1c-4d09-c348-196f1ba941eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image depicts a serene natural landscape featuring a wooden boardwalk path cutting through a vibrant green field. The sky is clear with a few scattered clouds, and the light suggests a time around sunrise or sunset, casting a warm glow across the scene. Trees and bushes can be seen in the distance, adding to the peaceful rural ambiance."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assistant processes the image and provides a descriptive response, which we display.\n",
        "\n"
      ],
      "metadata": {
        "id": "1UgmQr2hhuoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Key Concepts**\n",
        "* **Image Processing with OpenAI:** OpenAI's models can analyze and generate descriptions for images when provided with appropriate inputs.\n",
        "\n",
        "* **Content Types:** The assistant can handle different types of content, including text and images, by specifying the type in the content dictionary."
      ],
      "metadata": {
        "id": "OAhF2RjVhwY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Base64 Encoded Images"
      ],
      "metadata": {
        "id": "aFR0nK7Th26s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also provide images directly by encoding them in Base64."
      ],
      "metadata": {
        "id": "zuBm75mkh4zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os"
      ],
      "metadata": {
        "id": "bwzjX8JxhTkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"Thumbnail python FV1.jpg\"\n",
        "file_path = os.path.join(os.getcwd(), file_name)\n",
        "\n",
        "# Read the image and convert to base 64\n",
        "with open(file_path, \"rb\") as image_file:\n",
        "  image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "bc2KKV4DhVrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By encoding the image in Base64, we can include it directly in our API request without needing a publicly accessible URL."
      ],
      "metadata": {
        "id": "M_cLgRz9h69U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user content prompt\n",
        "user_content2 = [\n",
        "    {\"type\": \"text\",\n",
        "     \"text\": \"This is the image for my thumbnail for my Python for Data Analysis course. Be brutal, mean and provide sarcastic suggestions\"},\n",
        "    {\"type\": \"image_url\",\n",
        "     \"image_url\": {\n",
        "         \"url\": f\"data:image/jpeg;base64,{image_base64}\",\n",
        "         \"detail\": \"high\"\n",
        "     }}\n",
        "]"
      ],
      "metadata": {
        "id": "en_l4819jHvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We ask the assistant to critique the image sarcastically, providing both the prompt and the image data."
      ],
      "metadata": {
        "id": "2KYqOjB8h9eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a response using the Base64-encoded image\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_content2}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Display the assistant's response\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "5LHvbbZTjw-X",
        "outputId": "db165060-392c-4a07-9574-52406bd51a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Wow, this thumbnail is groundbreaking! Who knew data analysis involved snake charming? Clearly, your recorder skills are the secret sauce to mastering Python. The digital background is perfect if you're aiming for the aesthetic of a 2001 tech conference brochure. And that snake? It's practically a Disney sidekick! Maybe next time, have it hold a spreadsheet with its tail for extra impact. But hey, who doesn’t love a bit of nostalgia with those retro 1s and 0s? Truly inspirational!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assistant processes the Base64-encoded image and responds according to our prompt."
      ],
      "metadata": {
        "id": "SvCm7W4piBKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Key Concepts**\n",
        "* **Base64 Encoding**: Base64 is a method for encoding binary data into ASCII characters, making it safe to include in text-based formats like JSON.\n",
        "\n",
        "* **Data URIs**: By using a data URI scheme (data:image/jpeg;base64,...), we can include image data directly in the URL field, which is especially useful when the image is not hosted online."
      ],
      "metadata": {
        "id": "Qm5d5V-TiDFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "PjeGvldeiIou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we explored how to interact with the OpenAI API to generate text and analyze images.\n",
        "\n",
        "We learned how to set up the environment, define prompts, adjust parameters for text generation, and include images in our API requests.\n",
        "\n",
        "By understanding these key concepts, we can leverage the power of OpenAI's models for a variety of applications."
      ],
      "metadata": {
        "id": "7DEOc9i-iKB-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Im6cldmAiHAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}